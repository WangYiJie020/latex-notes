\documentclass{article}

% These are only here for the sake of this tutorial.
\usepackage{amsmath}
\usepackage[a4paper, margin=1in]{geometry}
\begin{document}

\newcommand{\tr}{\operatorname{tr}}
\newcommand{\rank}{\operatorname{rank}}

\title{Trick to get eigenvalue of Matrix 3x3 which can decompose to rank 1 matrix}
\author{}
\maketitle

\section{Introduction}

If a 3x3 matrix can be decomposed into a rank 1 matrix, it means that the matrix can be expressed as the outer product of two vectors. Such a matrix has some interesting properties, particularly regarding its eigenvalues.

when a 3x3 matrix \( \boldsymbol A \) can be written as:
\[
\boldsymbol A = \boldsymbol R +\boldsymbol I_3 = \boldsymbol\alpha \boldsymbol\beta^{T} + k\boldsymbol I_3
\] 
where \( \boldsymbol\alpha \) and \( \boldsymbol\beta \) are 3-dimensional vectors, and \( \boldsymbol I_3 \) is the 3x3 identity matrix. We can easily find the eigenvalues of \( \boldsymbol A \) by using the properties of rank 1 matrices.

\section{Eigenvalues of Rank 1 Matrices}
A rank 1 matrix \( \boldsymbol R = \boldsymbol\alpha \boldsymbol\beta^{T} \) has the following properties regarding its eigenvalues:
\begin{itemize}
		\item It has one non-zero eigenvalue, which is given by \( \lambda_1 = 
			\boldsymbol\beta^{T} \boldsymbol\alpha \) and the corresponding 
			eigenvector is \( \boldsymbol\alpha \).
			We can verify this by calculating: $\boldsymbol R \boldsymbol\alpha
			= (\boldsymbol\alpha \boldsymbol\beta^{T}) \boldsymbol\alpha$.
		\item The other two eigenvalues are zero and 
			their corresponding eigenvectors are the basis 
			of the null space of \( \boldsymbol R \).
			Since any vector \( \boldsymbol v \) that satisfies
			\( \boldsymbol\beta^{T} \boldsymbol v = 0 \) is an eigenvector 
			corresponding to the eigenvalue 0.
\end{itemize}

\section{Eigenvalues of the Matrix \( \boldsymbol A \)}
Now, let's consider the matrix \( \boldsymbol A = \boldsymbol R + k\boldsymbol I_3 \).
The eigenvalues of \( \boldsymbol A \) can be determined by adding \( k \) to each of the eigenvalues of \( \boldsymbol R \):
\begin{itemize}
		\item The first eigenvalue of \( \boldsymbol A \) is:
			\[
			\lambda_1' = \lambda_1 + k = \boldsymbol\beta^{T} \boldsymbol\alpha + k
			\]
			Since $\boldsymbol\beta^{T}\boldsymbol\alpha=\tr(\boldsymbol R)$ and $\tr(\boldsymbol A)=\tr(\boldsymbol R)+3k$, we have:
			\[
			\lambda_1' = \tr(\boldsymbol A) - 2k
			\]
		\item The second and third eigenvalue of \( \boldsymbol A \) is:
			\[
			\lambda_2'=\lambda_3' = \lambda_2 + k = k
			\]
\end{itemize}

\section{Trick to find k}

The value of \( k \) is not always easy to find directly by inspection.
But here is a trick to find \( k \) when the matrix \( \boldsymbol A \) is 3x3.

Since $\rank\boldsymbol R=1$, we have $\det(\boldsymbol A-k\boldsymbol I_3)=0$
that is:
\[
	\begin{vmatrix}
		a_{11}-k & a_{12} & a_{13} \\
		a_{21} & a_{22}-k & a_{23} \\
		a_{31} & a_{32} & a_{33}-k\\
	\end{vmatrix} = 0
\]

which means that there exists 2 rows are linearly dependent.
We can just assume the first row and second row are linearly dependent,
that require the determinant of right up $2\times2$ sub-matrix is zero:
\[
	\begin{vmatrix}
		a_{12} & a_{13} \\
		a_{22}-k & a_{23} \\
	\end{vmatrix} = 0
\]
which gives:
\[
	k = a_{22} - \frac{a_{23} a_{12}}{a_{13}} = \frac{a_{12} a_{23} - a_{13} a_{22}}{-a_{13}}
\]
Or more easy to remember form: 
\[
	k=\frac{\det(\text{right up 2x2 matrix})}
	{\text{negative of right top element}}
\]
It is same if we choose row 2 and row 3 are linearly dependent, we get:
\[
	k=\frac{\det(\text{left down 2x2 matrix})}
	{\text{negative of left bottom element}}
\]
But notice that this trick only gives possible value of \( k \),
we need to verify if the resulted \( \boldsymbol R = \boldsymbol A - k
\boldsymbol I_3 \) is indeed rank 1 matrix. And when the denominator is zero,
we need to try other pairs of rows.

\section{Calculation Example}

Find the eigenvalues and eigenvectors of the matrix:
\[
\boldsymbol A = \begin{bmatrix}
9 & 0 & 0 \\
-2 & 7 & -4 \\
-2 & -2 & 5 \\
\end{bmatrix}
\]

Using the trick to find \( k \):
\[
	k = \frac{\begin{vmatrix}
			-2 & 7\\
			-2 & -2
	\end{vmatrix}}{-2}
	= \frac{(4 + 14)}{2} = 9
\]
Substituting back to check \( \boldsymbol R \):
\[
\boldsymbol R = \boldsymbol A - 9 \boldsymbol I_3 =
\begin{bmatrix}
	0 & 0 & 0 \\
	-2 & -2 & -4 \\
	-2 & -2 & -4 \\
\end{bmatrix}
\]
which is indeed a rank 1 matrix.
Thus, the eigenvalues of \( \boldsymbol A \) are:
\[
\begin{aligned}
	\lambda_1 &= (9 + 7 + 5) - 18 = 3 \\
	\lambda_{2,3} &= 9
\end{aligned}
\]
Find the eigenvectors:
\begin{itemize}
		\item For \( \lambda_1 = 3 \), we can choose $\boldsymbol\alpha=(0,1,1)^{T}$ ,
			so the eigenvector is:
			\[
				\boldsymbol v_1 = \begin{bmatrix}
					0 \\ 1 \\ 1
				\end{bmatrix}
			\]
		\item For \( \lambda_{2,3} = 9 \), we can choose $\boldsymbol\beta^{T}= (1,1,2)$, 
			so the eigenvectors are such as:
			\[
				\boldsymbol v_2 = \begin{bmatrix}
					-1 \\ 1 \\ 0
				\end{bmatrix}, \quad
				\boldsymbol v_3 = \begin{bmatrix}
					-2 \\ 0 \\ 1
				\end{bmatrix}
			\]
\end{itemize}

\section{Formal answer format example}
Find the eigenvalues and eigenvectors of the matrix:
\[
\boldsymbol A = \begin{bmatrix}
	0 & -4 & -6\\
	-1 & 0 & -3\\
	1 & 2 & 5\\
\end{bmatrix}
\]

\textbf{In scratch paper:}

we can easily find \( k = 2 \) is a correct value.
with corresponding eigenvalues $1,2,2$. Also get 
\[\boldsymbol R = \begin{bmatrix}
	-2 & -4 & -6\\
	-1 & -2 & -3\\
	1 & 2 & 3\\
\end{bmatrix}
\]

and choose $\boldsymbol\alpha = (-2,-1,1)^{T}$ and $\boldsymbol\beta^{T} = (1,2,3)$.

\textbf{Answer:} 

The characteristic equation is

\[
	\begin{array}{c}
		|\lambda \boldsymbol I - \boldsymbol A| =
		(\lambda - 1)(\lambda - 2)^2 = 0
\end{array}
\] 

Thus, the eigenvalues are:
\[
\begin{aligned}
	\lambda_1 &= 1 \\
	\lambda_{2,3} &= 2
\end{aligned}
\]

When \( \lambda_1 = 1 \), solve \( (\boldsymbol A - \boldsymbol I) \boldsymbol v = 0 \), get
\[
\boldsymbol v_1 = \begin{bmatrix}
	-2 \\ -1 \\ 1
\end{bmatrix}
\]

When \( \lambda_{2,3} = 2 \), solve \( (\boldsymbol A - 2\boldsymbol I) \boldsymbol v = 0 \), get
\[
\boldsymbol v_2 = \begin{bmatrix}
	-2 \\ 1 \\ 0
\end{bmatrix}, 
\boldsymbol v_3 = \begin{bmatrix}
	-3 \\ 0 \\ 1
\end{bmatrix}
\]

\section{Not applicable cases}

Not all 3x3 matrices can be decomposed into a rank 1 matrix plus a scalar multiple of the identity matrix. But when $k$ can be found by the above trick, the $\boldsymbol R$ probably has 2 rows linearly dependent, which means $k$ is an eigenvalue of $\boldsymbol A$. But notice that's not always true.

\textbf{Example:} 

\[\boldsymbol A = \begin{bmatrix}
-1 & 4 & -2\\
-3 & 4 & 0\\
-3 & 1 &3\\
\end{bmatrix}\]

Using the trick to find \( k \):
\[
	k_{\text{upright}} = 4, \quad
	k_{\text{downleft}} = 3
\]

Substituting back to check \( \boldsymbol R \):
\[\boldsymbol R_{\text{upright}} = \begin{bmatrix}
-5 & 4 & -2\\
-3 & 0 & 0\\
-3 & 1 & -1\\
\end{bmatrix}, \quad
\boldsymbol R_{\text{downleft}} = \begin{bmatrix}
-4 & 4 & -2\\
-3 & 1 & 0\\
-3 & 1 & 0\\
\end{bmatrix}
\]

here one $k$ give appropriate eigenvalue, but $\boldsymbol R$ is not rank 1 matrix. and other $k$ failed, which neither give an eigenvalue nor rank 1 matrix.

\section{Conclusion}

In fact, this trick is a derivation from the trick to extract eigenvalue from 
$3\times3$ matrix which use method similar we find $k$ here to find $\lambda$:
assume two rows are linearly dependent, then solve for $\lambda$.

\end{document}
